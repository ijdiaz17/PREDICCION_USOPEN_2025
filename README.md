![image](./0_data/usopen.png)

# PredicciÃ³n del Ganador del US Open 2025

## Resumen del Proyecto
Se implementa un modelo de Machine Learning (ML) para simular y predecir el resultado del Ãºltimo Grand Slam del aÃ±o. Utilizamos una metodologÃ­a de Series Temporales y el MÃ©todo Monte Carlo para calcular la probabilidad de campeonato de cada jugador.  

El principal valor reside en la IngenierÃ­a de CaracterÃ­sticas retrospectivas y la ValidaciÃ³n CronolÃ³gica para construir un modelo robusto y libre de data leakage.  

## MetodologÃ­a Clave
Modelo de Habilidad DinÃ¡mica (Elo): se utiliza un rating Elo dinÃ¡mico y especÃ­fico por superficie (Elo_Surface_Diff) para medir la habilidad de un jugador justo antes de cada partido.  
ValidaciÃ³n Temporal: el entrenamiento se realizÃ³ en datos pasados y se probÃ³ en datos futuros (Train < 2016, Test > 2016) para asegurar que el modelo generalice.  
Rendimiento CientÃ­fico: el modelo Random Forest final logrÃ³ un ROC AUC de 0.72 en el set de prueba, demostrando una alta capacidad de discriminaciÃ³n del riesgo.  

## ðŸ“‚ Estructura del proyecto
El proyecto sigue una arquitectura modular para garantizar la separaciÃ³n de responsabilidades y la reproducibilidad.

```
/PREDICCION_USOPEN_2025
â”œâ”€â”€ 0_data/                 # Almacenamiento de datos y sets de entrenamiento
â”‚   â”œâ”€â”€ 0_raw/              # Datos originales (ej: atp_tennis.csv)
â”‚   â”œâ”€â”€ 1_processed/        # Datos con Feature Engineering (partidos_final.csv)
â”‚   â”œâ”€â”€ 2_train/            # X_train y y_train (datos <= 2016)
â”‚   â””â”€â”€ 3_test/             # X_test y y_test (datos >= 2016)
â”‚
â”œâ”€â”€ 1_notebooks/                                         # Desarrollo y experimentaciÃ³n
â”‚   â”œâ”€â”€ 01_Fuentes.ipynb                                 # AdquisiciÃ³n y uniÃ³n de datos.
â”‚   â”œâ”€â”€ 02_LimpiezaEDA.ipynb                             # Limpieza, EDA y Feature Engineering (Incluye TÃ­tulos DinÃ¡micos).
â”‚   â”œâ”€â”€ 03_Entrenamiento_Evaluacion.ipynb                # Tuning (Grid Search) y evaluaciÃ³n de modelos.
â”‚   â”œâ”€â”€ 04_Logica_determinista_montecarlo1.ipynb         # DeclaraciÃ³n de fx y lÃ³gicas para dos simulaciones
â”‚   â””â”€â”€ 04_Logica_montecarlo500.ipynb                    # DeclaraciÃ³n de fx y lÃ³gicas para simulaciÃ³n final
â”‚
â”œâ”€â”€ 3_models/                               # Modelos serializados
â”‚   â”œâ”€â”€ random_forest_modeloN.joblib        # Modelos intermedios del tuning.
â”‚   â”œâ”€â”€ random_forest_modelofinalOK.joblib  # Pipeline Random Forest final (Despliegue).
â”‚   â””â”€â”€ model_config.yaml                   # ConfiguraciÃ³n de hiperparÃ¡metros.
â”‚
â”œâ”€â”€ 4_app_streamlit/        # Despliegue de la AplicaciÃ³n Web
â”‚   â”œâ”€â”€ app.py              # CÃ³digo de la aplicaciÃ³n Streamlit.
â”‚   â”œâ”€â”€ main.py             # LÃ³gica de carga y estructura de datos.
â”‚   â”œâ”€â”€ utils.py            # Funciones auxiliares (H2H Caching, simulaciÃ³n).
â”‚   â””â”€â”€ requirements.txt    # Dependencias del proyecto.
â”‚
â”œâ”€â”€ 5_docs/
â”‚    â”œâ”€â”€ PRESENTACION JUEVES.pdf    
â”‚    â”œâ”€â”€ PRESENTACION VIERNES.pdf
â”‚    â”œâ”€â”€ simulacion_determinista.mp4
â”‚    â””â”€â”€ simulacion_montecarlo.mp4 
â”‚
â””â”€â”€â”€ README.md

```

---


## TecnologÃ­as y LibrerÃ­as
- **Python 3.11**
- **Pandas** 
- **NumPy** 
- **Matplotlib / Seaborn**
- **scikit-learn: Modelado y tuning (Random Forest).**
- **joblib: SerializaciÃ³n del modelo Pipeline.**

---

## Instrucciones de Despliegue

La aplicaciÃ³n ha sido desplegada exitosamente en Streamlit Community Cloud, asegurando la accesibilidad y el rendimiento de la arquitectura de caching optimizada.

Acceso Directo a la AplicaciÃ³n Web  
Puedes acceder a las dos versiones del modelo a travÃ©s de los siguientes enlaces:

SimulaciÃ³n Determinista (Camino MÃ¡s Probable): https://prediccionusopen2025determinista.streamlit.app/

SimulaciÃ³n Monte Carlo - 1 run (AnÃ¡lisis de Riesgo): https://prediccionusopen2025montecarlo.streamlit.app/

La simulaciÃ³n Monte Carlo de 500 runs no tiene app por cumplimiento de tiempos estipulados para la presentaciÃ³n en clase.

El despliegue utiliza @st.cache_resource para asegurar que la carga pesada del DataFrame y la pre-computaciÃ³n de los datos (H2H Caching) se ejecuten solo una vez en el servidor. Esto es clave para garantizar la alta velocidad de la interfaz.


Para ejecutar la aplicaciÃ³n interactiva y simular el torneo (usando la arquitectura de caching optimizada):  
- Clonar el respositorio
- Instalar Dependencias:  

```python
pip install -r 4_app_streamlit/requirements.txt

```

- Ejecutar la AplicaciÃ³n Streamlit:  

```python
streamlit run 4_app_streamlit/app.py

```
---

## ðŸ“š Autor
Proyecto realizado por **Ignacio DÃ­az**
